#!/usr/bin/env python3
"""
EOI-PL v1.0-Prime: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
-ç¦æ­¢äº‹é …: å½“æ—¥ã‚ªãƒƒã‚º/äººæ°—ã¯ä¸€åˆ‡ä½¿ç”¨ã—ãªã„ï¼ˆå­¦ç¿’ãƒ»æ¨è«–ãƒ»å‡ºåŠ›ã™ã¹ã¦ã§ç¦æ­¢ï¼‰
- ç›®çš„å¤‰æ•°: è¤‡å‹ãƒ•ãƒ©ã‚° (kakutei_chakujun <= 3)
"""

import pandas as pd
import numpy as np
from datetime import datetime
import psycopg2

class FeatureEngineering:
    """ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³"""
    
    # ğŸš¨ FORBIDDEN COLUMNS - çµ¶å¯¾ã«ä½¿ç”¨ç¦æ­¢
    FORBIDDEN_KEYWORDS = ['odds', 'ã‚ªãƒƒã‚º', 'äººæ°—', 'ninki', 'popularity']
    
    def __init__(self, conn):
        self.conn = conn
        
    def load_training_data(self, limit_date=None):
        """
        å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        limit_date: YYYYMMDDå½¢å¼ï¼ˆã“ã®æ—¥ä»˜ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
        """
        query = """
            SELECT 
                r.race_id,
                r.kaisai_nen,
                r.kaisai_tsukihi,
                r.keibajo_code,
                r.race_bango,
                r.kyori,
                r.track_code,
                r.babajotai_code_dirt,
                r.kyoso_joken_code,
                r.tosu,
                e.umaban,
                e.wakuban,
                e.bataiju,
                e.kakutei_chakujun,
                e.soha_time,
                e.corner_1,
                e.corner_2,
                e.corner_3,
                e.corner_4,
                e.kohan_3f,
                e.ketto_toroku_bango,
                e.kishu_code,
                e.chokyoshi_code
            FROM races r
            INNER JOIN entries e ON r.race_id = e.race_id
            WHERE e.kakutei_chakujun > 0  -- çµæœç¢ºå®šæ¸ˆã¿
        """
        
        if limit_date:
            query += f" AND r.kaisai_tsukihi <= {limit_date}"
        
        query += " ORDER BY r.kaisai_nen, r.kaisai_tsukihi, r.keibajo_code, r.race_bango, e.umaban"
        
        df = pd.read_sql(query, self.conn)
        print(f"âœ… Loaded {len(df):,} entries")
        
        # ç¦æ­¢ã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯
        self._check_forbidden_columns(df)
        
        return df
    
    def _check_forbidden_columns(self, df):
        """ç¦æ­¢ã‚«ãƒ©ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯"""
        forbidden = [col for col in df.columns 
                    if any(kw.lower() in col.lower() for kw in self.FORBIDDEN_KEYWORDS)]
        
        if forbidden:
            raise ValueError(f"ğŸš¨ FORBIDDEN COLUMNS DETECTED: {forbidden}")
        
        print("âœ… No forbidden columns (odds/popularity) detected")
    
    def create_features(self, df):
        """
        ç‰¹å¾´é‡ç”Ÿæˆ
        - ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±
        - é¦¬ã®éå»æˆç¸¾
        - é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®å®Ÿç¸¾
        - æ ãƒ»é¦¬ç•ªã®çµ±è¨ˆ
        """
        print("\nğŸ”§ Creating features...")
        
        # ç›®çš„å¤‰æ•°: è¤‡å‹ãƒ•ãƒ©ã‚° (1ç€ã€œ3ç€)
        df['target_place'] = (df['kakutei_chakujun'] <= 3).astype(int)
        
        # åŸºæœ¬ç‰¹å¾´é‡
        df = self._add_basic_features(df)
        
        # éå»æˆç¸¾ç‰¹å¾´é‡ï¼ˆæ™‚ç³»åˆ—é †ã«å‡¦ç†ï¼‰
        df = self._add_past_performance_features(df)
        
        # é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®å®Ÿç¸¾
        df = self._add_jockey_trainer_features(df)
        
        # æ ãƒ»é¦¬ç•ªã®çµ±è¨ˆ
        df = self._add_position_features(df)
        
        print(f"âœ… Features created: {len(df.columns)} columns")
        return df
    
    def _add_basic_features(self, df):
        """åŸºæœ¬ç‰¹å¾´é‡"""
        # è·é›¢ã‚«ãƒ†ã‚´ãƒª
        df['kyori_category'] = pd.cut(df['kyori'], 
                                      bins=[0, 1200, 1600, 2000, 3000], 
                                      labels=['çŸ­è·é›¢', 'ä¸­è·é›¢', 'ä¸­é•·è·é›¢', 'é•·è·é›¢'])
        
        # é¦¬å ´çŠ¶æ…‹ï¼ˆãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼‰
        df['baba_è‰¯'] = (df['babajotai_code_dirt'] == 1).astype(int)
        df['baba_ç¨é‡'] = (df['babajotai_code_dirt'] == 2).astype(int)
        df['baba_é‡'] = (df['babajotai_code_dirt'] == 3).astype(int)
        df['baba_ä¸è‰¯'] = (df['babajotai_code_dirt'] == 4).astype(int)
        
        # å‡ºèµ°é ­æ•°
        df['tosu_å°‘'] = (df['tosu'] <= 8).astype(int)
        df['tosu_å¤š'] = (df['tosu'] >= 12).astype(int)
        
        return df
    
    def _add_past_performance_features(self, df):
        """éå»æˆç¸¾ç‰¹å¾´é‡ï¼ˆæ™‚ç³»åˆ—è€ƒæ…®ï¼‰"""
        # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ
        df = df.sort_values(['kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'race_bango'])
        
        # é¦¬ã”ã¨ã®éå»æˆç¸¾é›†è¨ˆ
        df['horse_past_races'] = df.groupby('ketto_toroku_bango').cumcount()
        df['horse_past_wins'] = df.groupby('ketto_toroku_bango')['target_place'].cumsum()
        
        # éå»å‹ç‡ï¼ˆ0é™¤ç®—å›é¿ï¼‰
        df['horse_win_rate'] = np.where(
            df['horse_past_races'] > 0,
            df['horse_past_wins'] / df['horse_past_races'],
            0.0
        )
        
        # ç›´è¿‘3èµ°ã®æˆç¸¾
        df['horse_recent_3_avg_rank'] = (
            df.groupby('ketto_toroku_bango')['kakutei_chakujun']
            .transform(lambda x: x.rolling(3, min_periods=1).mean().shift(1))
        )
        
        return df
    
    def _add_jockey_trainer_features(self, df):
        """é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®å®Ÿç¸¾ç‰¹å¾´é‡"""
        # é¨æ‰‹ã®éå»å‹ç‡
        jockey_stats = df.groupby('kishu_code').agg({
            'target_place': ['count', 'sum']
        }).reset_index()
        jockey_stats.columns = ['kishu_code', 'jockey_races', 'jockey_wins']
        jockey_stats['jockey_win_rate'] = jockey_stats['jockey_wins'] / jockey_stats['jockey_races']
        
        df = df.merge(jockey_stats, on='kishu_code', how='left')
        
        # èª¿æ•™å¸«ã®éå»å‹ç‡
        trainer_stats = df.groupby('chokyoshi_code').agg({
            'target_place': ['count', 'sum']
        }).reset_index()
        trainer_stats.columns = ['chokyoshi_code', 'trainer_races', 'trainer_wins']
        trainer_stats['trainer_win_rate'] = trainer_stats['trainer_wins'] / trainer_stats['trainer_races']
        
        df = df.merge(trainer_stats, on='chokyoshi_code', how='left')
        
        return df
    
    def _add_position_features(self, df):
        """æ ãƒ»é¦¬ç•ªã®çµ±è¨ˆç‰¹å¾´é‡"""
        # æ ç•ªåˆ¥ã®è¤‡å‹ç‡
        wakuban_stats = df.groupby('wakuban').agg({
            'target_place': ['count', 'sum']
        }).reset_index()
        wakuban_stats.columns = ['wakuban', 'wakuban_races', 'wakuban_wins']
        wakuban_stats['wakuban_win_rate'] = wakuban_stats['wakuban_wins'] / wakuban_stats['wakuban_races']
        
        df = df.merge(wakuban_stats, on='wakuban', how='left')
        
        # é¦¬ç•ªåˆ¥ã®è¤‡å‹ç‡
        umaban_stats = df.groupby('umaban').agg({
            'target_place': ['count', 'sum']
        }).reset_index()
        umaban_stats.columns = ['umaban', 'umaban_races', 'umaban_wins']
        umaban_stats['umaban_win_rate'] = umaban_stats['umaban_wins'] / umaban_stats['umaban_races']
        
        df = df.merge(umaban_stats, on='umaban', how='left')
        
        return df
    
    def get_feature_columns(self):
        """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ä¸€è¦§"""
        return [
            # ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±
            'kyori', 'tosu',
            'baba_è‰¯', 'baba_ç¨é‡', 'baba_é‡', 'baba_ä¸è‰¯',
            'tosu_å°‘', 'tosu_å¤š',
            
            # é¦¬ã®éå»æˆç¸¾
            'horse_past_races', 'horse_win_rate', 'horse_recent_3_avg_rank',
            
            # é¨æ‰‹ãƒ»èª¿æ•™å¸«
            'jockey_win_rate', 'trainer_win_rate',
            
            # æ ãƒ»é¦¬ç•ª
            'wakuban', 'umaban', 'wakuban_win_rate', 'umaban_win_rate',
            
            # é¦¬ä½“é‡ï¼ˆæ¬ æå€¤ã¯å¹³å‡å€¤ã§è£œå®Œï¼‰
            'bataiju',
        ]


if __name__ == "__main__":
    # æ¥ç¶š
    conn = psycopg2.connect(
        host="localhost",
        database="eoi_pl",
        user="postgres",
        password="eoi_pl_dev"
    )
    
    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    fe = FeatureEngineering(conn)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆ2024å¹´æœ«ã¾ã§ï¼å­¦ç¿’ç”¨ï¼‰
    df = fe.load_training_data(limit_date=20241231)
    
    # ç‰¹å¾´é‡ç”Ÿæˆ
    df = fe.create_features(df)
    
    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    print("\nğŸ“‹ Feature Sample:")
    feature_cols = fe.get_feature_columns()
    print(df[feature_cols + ['target_place']].head(10))
    
    # æ¬ æå€¤ç¢ºèª
    print("\nğŸ“Š Missing Values:")
    print(df[feature_cols].isnull().sum()[df[feature_cols].isnull().sum() > 0])
    
    # ä¿å­˜
    output_path = "/home/user/eoi-pl/data/training_features.parquet"
    df.to_parquet(output_path, index=False)
    print(f"\nâœ… Features saved to {output_path}")
    print(f"   Shape: {df.shape}")
    
    conn.close()
