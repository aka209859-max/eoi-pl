#!/usr/bin/env python3
"""
EOI-PL v1.0-Prime: äºˆæƒ³ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆçµ±åˆç‰ˆï¼‰
- DBèª­ã¿è¾¼ã¿ â†’ ç‰¹å¾´é‡ç”Ÿæˆ â†’ äºˆæ¸¬ â†’ æ¨å¥¨åº¦ä»˜ä¸ â†’ JSONå‡ºåŠ›
"""

import pandas as pd
import numpy as np
import psycopg2
import pickle
import json
from datetime import datetime
import sys

sys.path.append('/home/user/eoi-pl/src/features')
sys.path.append('/home/user/eoi-pl/src/grading')

from mvp_features import get_feature_columns
from grading_engine import GradingEngine

class PredictionEngine:
    """äºˆæƒ³ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, model_path, calibrator_path, conn):
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        with open(model_path, 'rb') as f:
            self.model = pickle.load(f)
        
        with open(calibrator_path, 'rb') as f:
            self.calibrator = pickle.load(f)
        
        self.conn = conn
        self.feature_cols = get_feature_columns()
        self.grading_engine = GradingEngine()
        
        print(f"âœ… Model loaded: {model_path}")
        print(f"âœ… Calibrator loaded: {calibrator_path}")
    
    def load_target_races(self, target_date):
        """
        äºˆæƒ³å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿
        target_date: YYYYMMDDå½¢å¼
        """
        query = f"""
            SELECT 
                r.race_id,
                r.kaisai_nen,
                r.kaisai_tsukihi,
                r.keibajo_code,
                r.race_bango,
                r.kyori,
                r.track_code,
                r.babajotai_code_dirt,
                r.tosu,
                e.umaban,
                e.wakuban,
                e.bataiju,
                e.ketto_toroku_bango,
                e.kishu_code,
                e.chokyoshi_code,
                e.bamei
            FROM races r
            INNER JOIN entries e ON r.race_id = e.race_id
            WHERE r.kaisai_tsukihi = {target_date}
            ORDER BY r.keibajo_code, r.race_bango, e.umaban
        """
        
        df = pd.read_sql(query, self.conn)
        
        if len(df) == 0:
            raise ValueError(f"No races found for date {target_date}")
        
        n_races = df['race_id'].nunique()
        print(f"âœ… Loaded {len(df)} entries from {n_races} races")
        return df
    
    def create_features_for_prediction(self, df):
        """äºˆæ¸¬ç”¨ç‰¹å¾´é‡ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # åŸºæœ¬ç‰¹å¾´é‡
        df['kyori_short'] = (df['kyori'] < 1400).astype(int)
        df['kyori_long'] = (df['kyori'] > 1800).astype(int)
        df['baba_good'] = (df['babajotai_code_dirt'] == 1).astype(int)
        df['tosu_many'] = (df['tosu'] >= 12).astype(int)
        
        # é¦¬ä½“é‡ï¼ˆæ¬ æå€¤ã¯ä¸­å¤®å€¤ï¼‰
        df['bataiju'] = df['bataiju'].fillna(475.0)
        
        # éå»æˆç¸¾ï¼ˆç°¡æ˜“ç‰ˆ: å…¨ä½“çµ±è¨ˆã§ä»£ç”¨ï¼‰
        df['horse_win_rate'] = 0.30  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        df['jockey_win_rate'] = 0.30
        df['trainer_win_rate'] = 0.30
        df['wakuban_win_rate'] = 0.30
        df['umaban_win_rate'] = 0.30
        
        return df
    
    def predict_place_probabilities(self, df):
        """è¤‡å‹ç¢ºç‡äºˆæ¸¬"""
        X = df[self.feature_cols]
        
        # æœªæ ¡æ­£ç¢ºç‡
        P_place_raw = self.model.predict(X)
        
        # æ ¡æ­£
        P_place_cal = self.calibrator.transform(P_place_raw)
        P_place_cal = np.clip(P_place_cal, 0.001, 0.999)
        
        df['P_place_raw'] = P_place_raw
        df['P_place_cal'] = P_place_cal
        
        # å˜å‹ç¢ºç‡ï¼ˆç°¡æ˜“è¨ˆç®—: è¤‡å‹ç¢ºç‡ã®2ä¹—ï¼‰
        df['P_win_cal'] = df['P_place_cal'] ** 1.5
        
        # ãƒ¬ãƒ¼ã‚¹å†…ã§æ­£è¦åŒ–
        for race_id in df['race_id'].unique():
            mask = df['race_id'] == race_id
            df.loc[mask, 'P_win_cal'] = df.loc[mask, 'P_win_cal'] / df.loc[mask, 'P_win_cal'].sum()
        
        return df
    
    def assign_grades_all_races(self, df):
        """å…¨ãƒ¬ãƒ¼ã‚¹ã«æ¨å¥¨åº¦ã‚’ä»˜ä¸"""
        result_dfs = []
        
        for race_id in df['race_id'].unique():
            race_df = df[df['race_id'] == race_id].copy()
            race_df = self.grading_engine.assign_grades(race_df)
            result_dfs.append(race_df)
        
        return pd.concat(result_dfs, ignore_index=True)
    
    def generate_json_output(self, df, target_date):
        """JSONå‡ºåŠ›ç”Ÿæˆ"""
        output = {
            'generated_at': datetime.now().isoformat(),
            'target_date': target_date,
            'policy': {
                'odds_used': False,
                'freeze': True,
                'coverage_scheme': 'A',
                'thresholds': self.grading_engine.THRESHOLDS
            },
            'races': []
        }
        
        for race_id in sorted(df['race_id'].unique()):
            race_df = df[df['race_id'] == race_id]
            
            race_info = race_df.iloc[0]
            
            race_output = {
                'race_id': race_id,
                'race_meta': {
                    'kaisai_nen': int(race_info['kaisai_nen']),
                    'kaisai_tsukihi': int(race_info['kaisai_tsukihi']),
                    'keibajo_code': int(race_info['keibajo_code']),
                    'race_bango': int(race_info['race_bango']),
                    'kyori': int(race_info['kyori']),
                    'tosu': int(race_info['tosu'])
                },
                'horses': []
            }
            
            for _, horse in race_df.iterrows():
                horse_output = {
                    'umaban': int(horse['umaban']),
                    'bamei': str(horse['bamei']).strip(),
                    'P_win_cal': round(float(horse['P_win_cal']), 4),
                    'P_place_cal': round(float(horse['P_place_cal']), 4),
                    'grade': horse['grade'],
                    'ketto_toroku_bango': str(horse['ketto_toroku_bango']),
                    'kishu_code': int(horse['kishu_code']),
                    'chokyoshi_code': int(horse['chokyoshi_code'])
                }
                race_output['horses'].append(horse_output)
            
            # é¦¬ç•ªé †ã«ã‚½ãƒ¼ãƒˆ
            race_output['horses'] = sorted(race_output['horses'], key=lambda x: x['umaban'])
            
            output['races'].append(race_output)
        
        return output

def main(target_date):
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print(f"\n{'='*60}")
    print(f"ğŸ‡ EOI-PL v1.0-Prime: äºˆæƒ³ç”Ÿæˆ")
    print(f"   Target Date: {target_date}")
    print(f"{'='*60}\n")
    
    # DBæ¥ç¶š
    conn = psycopg2.connect(
        host="localhost",
        database="eoi_pl",
        user="postgres",
        password="eoi_pl_dev"
    )
    
    try:
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        engine = PredictionEngine(
            model_path="/home/user/eoi-pl/models/lgbm_place_model.pkl",
            calibrator_path="/home/user/eoi-pl/models/calibrator.pkl",
            conn=conn
        )
        
        # ãƒ¬ãƒ¼ã‚¹èª­ã¿è¾¼ã¿
        df = engine.load_target_races(target_date)
        
        # ç‰¹å¾´é‡ç”Ÿæˆ
        print("\nğŸ”§ Creating features...")
        df = engine.create_features_for_prediction(df)
        
        # äºˆæ¸¬
        print("ğŸ”® Predicting place probabilities...")
        df = engine.predict_place_probabilities(df)
        
        # æ¨å¥¨åº¦ä»˜ä¸
        print("ğŸ“Š Assigning grades (Coverage A)...")
        df = engine.assign_grades_all_races(df)
        
        # JSONç”Ÿæˆ
        print("ğŸ“ Generating JSON output...")
        output = engine.generate_json_output(df, target_date)
        
        # ä¿å­˜
        output_path = f"/home/user/eoi-pl/data/predictions_{target_date}.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… Predictions saved to {output_path}")
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print(f"\nğŸ“Š Summary:")
        print(f"   Total races: {len(output['races'])}")
        print(f"   Total horses: {sum(len(r['horses']) for r in output['races'])}")
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ
        all_grades = [h['grade'] for r in output['races'] for h in r['horses']]
        grade_dist = pd.Series(all_grades).value_counts().sort_index()
        print(f"\n   Grade Distribution:")
        for grade, count in grade_dist.items():
            pct = count / len(all_grades) * 100
            print(f"     {grade}: {count} ({pct:.1f}%)")
        
        print(f"\n{'='*60}")
        print("âœ… PREDICTION COMPLETED")
        print(f"{'='*60}\n")
        
    finally:
        conn.close()

if __name__ == "__main__":
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2025å¹´1æœˆ1æ—¥
    target_date = 20250101
    
    if len(sys.argv) > 1:
        target_date = int(sys.argv[1])
    
    main(target_date)
