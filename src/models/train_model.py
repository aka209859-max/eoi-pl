#!/usr/bin/env python3
"""
EOI-PL v1.0-Prime: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ + ç¢ºç‡æ ¡æ­£
- LightGBM: è¤‡å‹ç¢ºç‡äºˆæ¸¬
- Isotonic Regression: ç¢ºç‡æ ¡æ­£
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import roc_auc_score, log_loss
import pickle
import json
import sys

sys.path.append('/home/user/eoi-pl/src/features')
from mvp_features import get_feature_columns

def train_model(df, feature_cols):
    """LightGBMãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
    print("\nğŸš‚ Training LightGBM model...")
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆæ™‚ç³»åˆ—è€ƒæ…®ï¼‰
    X = df[feature_cols]
    y = df['target_place']
    
    # 2024å¹´=Train, 2025å¹´=Test
    train_mask = df['kaisai_nen'] == 2024
    test_mask = df['kaisai_nen'] == 2025
    
    X_train, y_train = X[train_mask], y[train_mask]
    X_test, y_test = X[test_mask], y[test_mask]
    
    print(f"  Train: {len(X_train):,} samples")
    print(f"  Test:  {len(X_test):,} samples")
    
    # LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¤‡å‹ç¢ºç‡äºˆæ¸¬ç”¨ï¼‰
    params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'max_depth': 6,
        'min_data_in_leaf': 50,
        'verbose': -1
    }
    
    # Datasetä½œæˆ
    lgb_train = lgb.Dataset(X_train, y_train)
    lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)
    
    # å­¦ç¿’
    model = lgb.train(
        params,
        lgb_train,
        num_boost_round=500,
        valid_sets=[lgb_train, lgb_test],
        valid_names=['train', 'test'],
        callbacks=[
            lgb.early_stopping(stopping_rounds=50, verbose=False),
            lgb.log_evaluation(period=100)
        ]
    )
    
    # äºˆæ¸¬ï¼ˆæœªæ ¡æ­£ç¢ºç‡ï¼‰
    y_pred_train_raw = model.predict(X_train, num_iteration=model.best_iteration)
    y_pred_test_raw = model.predict(X_test, num_iteration=model.best_iteration)
    
    # è©•ä¾¡
    train_auc = roc_auc_score(y_train, y_pred_train_raw)
    test_auc = roc_auc_score(y_test, y_pred_test_raw)
    train_logloss = log_loss(y_train, y_pred_train_raw)
    test_logloss = log_loss(y_test, y_pred_test_raw)
    
    print(f"\nğŸ“Š Model Performance (Uncalibrated):")
    print(f"  Train AUC: {train_auc:.4f}, LogLoss: {train_logloss:.4f}")
    print(f"  Test  AUC: {test_auc:.4f}, LogLoss: {test_logloss:.4f}")
    
    return model, X_train, y_train, X_test, y_test, y_pred_train_raw, y_pred_test_raw

def calibrate_probabilities(model, X_train, y_train, X_test, y_test):
    """ç¢ºç‡æ ¡æ­£ï¼ˆIsotonic Regressionï¼‰"""
    print("\nğŸ”§ Calibrating probabilities (Isotonic Regression)...")
    
    # LightGBMã‚’sklearnäº’æ›ã®Wrapperã«
    from sklearn.base import BaseEstimator, ClassifierMixin
    
    class LGBMWrapper(BaseEstimator, ClassifierMixin):
        def __init__(self, model):
            self.model = model
            self.classes_ = np.array([0, 1])
        
        def fit(self, X, y):
            # Already fitted
            return self
        
        def predict_proba(self, X):
            preds = self.model.predict(X)
            return np.vstack([1 - preds, preds]).T
        
        def predict(self, X):
            return (self.predict_proba(X)[:, 1] > 0.5).astype(int)
    
    lgbm_wrapper = LGBMWrapper(model)
    
    # Isotonicæ ¡æ­£
    calibrated_model = CalibratedClassifierCV(
        lgbm_wrapper,
        method='isotonic',
        cv='prefit'
    )
    calibrated_model.fit(X_train, y_train)
    
    # æ ¡æ­£å¾Œç¢ºç‡
    y_pred_train_cal = calibrated_model.predict_proba(X_train)[:, 1]
    y_pred_test_cal = calibrated_model.predict_proba(X_test)[:, 1]
    
    # æ ¡æ­£å¾Œè©•ä¾¡
    train_auc_cal = roc_auc_score(y_train, y_pred_train_cal)
    test_auc_cal = roc_auc_score(y_test, y_pred_test_cal)
    train_logloss_cal = log_loss(y_train, y_pred_train_cal)
    test_logloss_cal = log_loss(y_test, y_pred_test_cal)
    
    print(f"\nğŸ“Š Model Performance (Calibrated):")
    print(f"  Train AUC: {train_auc_cal:.4f}, LogLoss: {train_logloss_cal:.4f}")
    print(f"  Test  AUC: {test_auc_cal:.4f}, LogLoss: {test_logloss_cal:.4f}")
    
    return calibrated_model, y_pred_train_cal, y_pred_test_cal

def analyze_calibration(y_true, y_pred_raw, y_pred_cal, name="Test"):
    """æ ¡æ­£åŠ¹æœã®åˆ†æ"""
    print(f"\nğŸ“Š Calibration Analysis ({name}):")
    
    # ç¢ºç‡ã‚’10åˆ†ä½ã«åˆ†å‰²ã—ã¦å®Ÿéš›ã®è¤‡å‹ç‡ã¨æ¯”è¼ƒ
    bins = np.linspace(0, 1, 11)
    
    print("  Predicted vs Actual (Uncalibrated):")
    for i in range(10):
        mask = (y_pred_raw >= bins[i]) & (y_pred_raw < bins[i+1])
        if mask.sum() > 0:
            actual_rate = y_true[mask].mean()
            pred_mean = y_pred_raw[mask].mean()
            print(f"    [{bins[i]:.1f}-{bins[i+1]:.1f}]: Pred={pred_mean:.3f}, Actual={actual_rate:.3f}, N={mask.sum():,}")
    
    print("\n  Predicted vs Actual (Calibrated):")
    for i in range(10):
        mask = (y_pred_cal >= bins[i]) & (y_pred_cal < bins[i+1])
        if mask.sum() > 0:
            actual_rate = y_true[mask].mean()
            pred_mean = y_pred_cal[mask].mean()
            print(f"    [{bins[i]:.1f}-{bins[i+1]:.1f}]: Pred={pred_mean:.3f}, Actual={actual_rate:.3f}, N={mask.sum():,}")

if __name__ == "__main__":
    # ç‰¹å¾´é‡èª­ã¿è¾¼ã¿
    print("ğŸ“¥ Loading features...")
    df = pd.read_parquet("/home/user/eoi-pl/data/training_features.parquet")
    feature_cols = get_feature_columns()
    
    print(f"  Shape: {df.shape}")
    print(f"  Features: {len(feature_cols)}")
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model, X_train, y_train, X_test, y_test, y_pred_train_raw, y_pred_test_raw = train_model(df, feature_cols)
    
    # ç¢ºç‡æ ¡æ­£
    calibrated_model, y_pred_train_cal, y_pred_test_cal = calibrate_probabilities(
        model, X_train, y_train, X_test, y_test
    )
    
    # æ ¡æ­£åŠ¹æœã®åˆ†æ
    analyze_calibration(y_test.values, y_pred_test_raw, y_pred_test_cal, name="Test")
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model_path = "/home/user/eoi-pl/models/lgbm_place_model.pkl"
    calibrated_model_path = "/home/user/eoi-pl/models/calibrated_place_model.pkl"
    
    import os
    os.makedirs("/home/user/eoi-pl/models", exist_ok=True)
    
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    
    with open(calibrated_model_path, 'wb') as f:
        pickle.dump(calibrated_model, f)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    metadata = {
        'model_type': 'LightGBM + Isotonic Calibration',
        'target': 'place (1-3rd)',
        'features': feature_cols,
        'train_samples': len(X_train),
        'test_samples': len(X_test),
        'train_auc': float(roc_auc_score(y_train, y_pred_train_cal)),
        'test_auc': float(roc_auc_score(y_test, y_pred_test_cal)),
        'train_logloss': float(log_loss(y_train, y_pred_train_cal)),
        'test_logloss': float(log_loss(y_test, y_pred_test_cal)),
        'created_at': pd.Timestamp.now().isoformat()
    }
    
    with open("/home/user/eoi-pl/models/model_metadata.json", 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"\n{'='*60}")
    print("âœ… MODEL TRAINING COMPLETED")
    print(f"{'='*60}")
    print(f"  Uncalibrated model: {model_path}")
    print(f"  Calibrated model:   {calibrated_model_path}")
    print(f"  Metadata:           /home/user/eoi-pl/models/model_metadata.json")
    print(f"{'='*60}\n")
