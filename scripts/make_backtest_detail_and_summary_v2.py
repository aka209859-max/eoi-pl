#!/usr/bin/env python3
"""
Generate backtest_summary_v2 with extended metrics
Top3@1/2/3, Top5@1/3 ã‚’ç›£æŸ»å¯èƒ½ãªå½¢ã§ç®—å‡º
"""

import os
import hashlib
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import pytz

JST = pytz.timezone('Asia/Tokyo')
PROJECT_ROOT = Path("/home/user/eoi-pl")
BACKTEST_DIR = PROJECT_ROOT / "backtest"

# ---- utilities ----
def sha256_file(path):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®SHA256ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()

def parse_set(s):
    """'8|5|2' â†’ {8, 5, 2}"""
    if pd.isna(s) or str(s).strip() == "":
        return set()
    return set(int(x) for x in str(s).split("|") if x != "")

def inter_k(a, b):
    """äº¤é›†åˆã®ã‚µã‚¤ã‚º"""
    return len(parse_set(a) & parse_set(b))

def main():
    print("=" * 70)
    print("Generate backtest_summary_v2 (Extended Metrics)")
    print("=" * 70)
    
    # ---- 1) load backtest_detail.csv ----
    detail_path = BACKTEST_DIR / "backtest_detail.csv"
    if not detail_path.exists():
        raise SystemExit(
            f"âŒ {detail_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
            "ã¾ãš scripts/generate_backtest_detail.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        )
    
    df = pd.read_csv(detail_path)
    print(f"\nâœ… Loaded: {detail_path}")
    print(f"   Total races: {len(df)}")
    
    # ---- 2) compute ks ----
    print("\nğŸ“Š Computing intersection sizes...")
    df["top3_k"] = df.apply(lambda r: inter_k(r["pred_top3"], r["actual_top3"]), axis=1)
    df["top5_k"] = df.apply(lambda r: inter_k(r["pred_top5"], r["actual_top5"]), axis=1)
    
    # ---- 3) daily aggregation ----
    def agg_day(g):
        races = len(g)
        return pd.Series({
            "races": races,
            "top3_at1_hits": int((g["top3_k"] >= 1).sum()),
            "top3_at2_hits": int((g["top3_k"] >= 2).sum()),
            "top3_at3_hits": int((g["top3_k"] >= 3).sum()),
            "top5_at1_hits": int((g["top5_k"] >= 1).sum()),
            "top5_at3_hits": int((g["top5_k"] >= 3).sum()),
            "top3_at1_rate": float((g["top3_k"] >= 1).mean()),
            "top3_at2_rate": float((g["top3_k"] >= 2).mean()),
            "top3_at3_rate": float((g["top3_k"] >= 3).mean()),
            "top5_at1_rate": float((g["top5_k"] >= 1).mean()),
            "top5_at3_rate": float((g["top5_k"] >= 3).mean()),
        })
    
    print("ğŸ“Š Aggregating by date...")
    daily = df.groupby("date", as_index=False).apply(agg_day).reset_index(drop=True)
    
    # ---- 4) total row ----
    total = agg_day(df)
    total_row = pd.DataFrame([{
        "date": "TOTAL",
        **total.to_dict()
    }])
    
    out = pd.concat([daily, total_row], ignore_index=True)
    
    # ---- 5) attach data_hash ----
    detail_hash = sha256_file(detail_path)
    out["data_hash"] = detail_hash[:16]  # çŸ­ç¸®ç‰ˆ
    
    # ---- 6) save CSV ----
    out_csv = BACKTEST_DIR / "backtest_summary_v2.csv"
    out.to_csv(out_csv, index=False)
    print(f"\nâœ… Saved: {out_csv}")
    
    # ---- 7) verification against backtest_summary.csv ----
    print("\n" + "=" * 70)
    print("Verification against backtest_summary.csv")
    print("=" * 70)
    
    old_csv = BACKTEST_DIR / "backtest_summary.csv"
    if old_csv.exists():
        old_df = pd.read_csv(old_csv)
        old_total = old_df[old_df['date'] == 'TOTAL'].iloc[0]
        new_total = out[out['date'] == 'TOTAL'].iloc[0]
        
        # Top3@1 should equal old top3_hits
        old_top3_hits = int(old_total['top3_hits'])
        new_top3_at1_hits = int(new_total['top3_at1_hits'])
        
        # Top5@1 should equal old top5_hits
        old_top5_hits = int(old_total['top5_hits'])
        new_top5_at1_hits = int(new_total['top5_at1_hits'])
        
        print(f"\nTop3@1 verification:")
        print(f"  Old top3_hits: {old_top3_hits}")
        print(f"  New top3_at1_hits: {new_top3_at1_hits}")
        if old_top3_hits == new_top3_at1_hits:
            print(f"  âœ… MATCH")
        else:
            raise SystemExit(f"  âŒ MISMATCH - Bug detected!")
        
        print(f"\nTop5@1 verification:")
        print(f"  Old top5_hits: {old_top5_hits}")
        print(f"  New top5_at1_hits: {new_top5_at1_hits}")
        if old_top5_hits == new_top5_at1_hits:
            print(f"  âœ… MATCH")
        else:
            raise SystemExit(f"  âŒ MISMATCH - Bug detected!")
    
    # ---- 8) save JSON ----
    out_json = BACKTEST_DIR / "backtest_summary_v2.json"
    json_data = {
        "meta": {
            "generated_at": datetime.now(JST).isoformat(),
            "model_version": "v1.0-PL-PowerEP",
            "detail_sha256": detail_hash,
            "total_races": int(new_total['races'])
        },
        "metrics": {
            "top3_at1": {
                "hits": int(new_total['top3_at1_hits']),
                "rate": float(new_total['top3_at1_rate']),
                "definition": "|PredTop3 âˆ© ActualTop3| â‰¥ 1"
            },
            "top3_at2": {
                "hits": int(new_total['top3_at2_hits']),
                "rate": float(new_total['top3_at2_rate']),
                "definition": "|PredTop3 âˆ© ActualTop3| â‰¥ 2"
            },
            "top3_at3": {
                "hits": int(new_total['top3_at3_hits']),
                "rate": float(new_total['top3_at3_rate']),
                "definition": "|PredTop3 âˆ© ActualTop3| = 3 (å®Œå…¨ä¸€è‡´)"
            },
            "top5_at1": {
                "hits": int(new_total['top5_at1_hits']),
                "rate": float(new_total['top5_at1_rate']),
                "definition": "|PredTop5 âˆ© ActualTop5| â‰¥ 1"
            },
            "top5_at3": {
                "hits": int(new_total['top5_at3_hits']),
                "rate": float(new_total['top5_at3_rate']),
                "definition": "|PredTop5 âˆ© ActualTop5| â‰¥ 3"
            }
        },
        "daily": out[out['date'] != 'TOTAL'].to_dict('records')
    }
    
    with open(out_json, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… Saved: {out_json}")
    
    # ---- 9) save Markdown report ----
    out_md = BACKTEST_DIR / "backtest_report_v2.md"
    
    report = f"""# Backtest Report v2 - Extended Metrics

**Generated**: {datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')} JST  
**Model**: PL+PowerEP (Î±=0.5)  
**SSOT**: v1.0-ssot  
**Detail SHA256**: {detail_hash}

---

## æŒ‡æ¨™å®šç¾©

### Top3@k: äºˆæ¸¬Top3ã¨å®Ÿéš›Top3ã®äº¤é›†åˆã‚µã‚¤ã‚º

- **Top3@1**: |PredTop3 âˆ© ActualTop3| â‰¥ 1ï¼ˆå°‘ãªãã¨ã‚‚1é ­ä¸€è‡´ï¼‰
- **Top3@2**: |PredTop3 âˆ© ActualTop3| â‰¥ 2ï¼ˆå°‘ãªãã¨ã‚‚2é ­ä¸€è‡´ï¼‰
- **Top3@3**: |PredTop3 âˆ© ActualTop3| = 3ï¼ˆå®Œå…¨ä¸€è‡´ã€é †ä¸åŒï¼‰

### Top5@k: äºˆæ¸¬Top5ã¨å®Ÿéš›Top5ã®äº¤é›†åˆã‚µã‚¤ã‚º

- **Top5@1**: |PredTop5 âˆ© ActualTop5| â‰¥ 1ï¼ˆå°‘ãªãã¨ã‚‚1é ­ä¸€è‡´ï¼‰
- **Top5@3**: |PredTop5 âˆ© ActualTop5| â‰¥ 3ï¼ˆå°‘ãªãã¨ã‚‚3é ­ä¸€è‡´ï¼‰

---

## å…¨ä½“çµæœï¼ˆTOTALï¼‰

| æŒ‡æ¨™ | å‘½ä¸­æ•° | å‘½ä¸­ç‡ | å®šç¾© |
|------|--------|--------|------|
| **Top3@1** | {int(new_total['top3_at1_hits'])} / {int(new_total['races'])} | **{new_total['top3_at1_rate']*100:.1f}%** | å°‘ãªãã¨ã‚‚1é ­ä¸€è‡´ |
| **Top3@2** | {int(new_total['top3_at2_hits'])} / {int(new_total['races'])} | **{new_total['top3_at2_rate']*100:.1f}%** | å°‘ãªãã¨ã‚‚2é ­ä¸€è‡´ |
| **Top3@3** | {int(new_total['top3_at3_hits'])} / {int(new_total['races'])} | **{new_total['top3_at3_rate']*100:.1f}%** | å®Œå…¨ä¸€è‡´ï¼ˆé †ä¸åŒï¼‰ |
| **Top5@1** | {int(new_total['top5_at1_hits'])} / {int(new_total['races'])} | **{new_total['top5_at1_rate']*100:.1f}%** | å°‘ãªãã¨ã‚‚1é ­ä¸€è‡´ |
| **Top5@3** | {int(new_total['top5_at3_hits'])} / {int(new_total['races'])} | **{new_total['top5_at3_rate']*100:.1f}%** | å°‘ãªãã¨ã‚‚3é ­ä¸€è‡´ |

---

## æ¤œè¨¼çµæœ

### æ—¢å­˜ backtest_summary.csv ã¨ã®çªåˆ

- âœ… **Top3@1 = old.top3_hits**: {old_top3_hits} = {new_top3_at1_hits} â†’ MATCH
- âœ… **Top5@1 = old.top5_hits**: {old_top5_hits} = {new_top5_at1_hits} â†’ MATCH

---

## å†ç¾æ‰‹é †

### Step 1: è©³ç´°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
```bash
python3 scripts/generate_backtest_detail.py
```

### Step 2: é›†è¨ˆï¼ˆæœ¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰
```bash
python3 scripts/make_backtest_detail_and_summary_v2.py
```

### æˆæœç‰©
- `backtest/backtest_detail.csv` ({len(df)}ãƒ¬ãƒ¼ã‚¹)
- `backtest/backtest_summary_v2.csv` (æ—¥åˆ¥+TOTAL)
- `backtest/backtest_summary_v2.json` (ç›£æŸ»ç”¨)
- `backtest/backtest_report_v2.md` (æœ¬ãƒ¬ãƒãƒ¼ãƒˆ)

### SHA256
- detail.csv: `{detail_hash}`
- summary_v2.csv: `{sha256_file(out_csv)}`

---

## å¤–éƒ¨æ¤œè¨¼

```bash
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
wget https://raw.githubusercontent.com/aka209859-max/eoi-pl/main/backtest/backtest_detail.csv
wget https://raw.githubusercontent.com/aka209859-max/eoi-pl/main/backtest/backtest_summary_v2.csv

# æ¤œè¨¼
sha256sum backtest_detail.csv
sha256sum backtest_summary_v2.csv

# æ‰‹è¨ˆç®—ç¢ºèª
python3 << 'EOF'
import pandas as pd
df = pd.read_csv('backtest_detail.csv')
def parse_set(s):
    if pd.isna(s) or str(s).strip() == "":
        return set()
    return set(int(x) for x in str(s).split("|") if x != "")

df['top3_k'] = df.apply(lambda r: len(parse_set(r['pred_top3']) & parse_set(r['actual_top3'])), axis=1)
print(f"Top3@1: {{(df['top3_k'] >= 1).sum()}} / {{len(df)}} = {{(df['top3_k'] >= 1).mean():.4f}}")
print(f"Top3@2: {{(df['top3_k'] >= 2).sum()}} / {{len(df)}} = {{(df['top3_k'] >= 2).mean():.4f}}")
print(f"Top3@3: {{(df['top3_k'] >= 3).sum()}} / {{len(df)}} = {{(df['top3_k'] >= 3).mean():.4f}}")
EOF
```

---

**Status**: âœ… å®Œäº†  
**Generated**: {datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')} JST
"""
    
    with open(out_md, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… Saved: {out_md}")
    
    # ---- 10) Final summary ----
    print("\n" + "=" * 70)
    print("TOTAL Results (backtest_summary_v2.csv)")
    print("=" * 70)
    print(out[out['date'] == 'TOTAL'].to_string(index=False))
    
    print("\n" + "=" * 70)
    print("SHA256 Hashes")
    print("=" * 70)
    print(f"backtest_detail.csv:     {detail_hash}")
    print(f"backtest_summary_v2.csv: {sha256_file(out_csv)}")
    print(f"backtest_summary_v2.json: {sha256_file(out_json)}")
    
    print("\n" + "=" * 70)
    print("âœ… All tasks completed successfully")
    print("=" * 70)
    
    return 0

if __name__ == "__main__":
    exit(main())
