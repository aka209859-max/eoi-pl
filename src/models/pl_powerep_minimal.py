#!/usr/bin/env python3
"""
Plackett-Luce + Power EP Minimal Implementation
CEO Directive: v1.0 SSOT - PL+PowerEPå¿…é ˆï¼ˆå¦¥å”ã‚¼ãƒ­ï¼‰

References:
- Power EP for PL: https://icml.cc/Conferences/2009/papers/347.pdf
- ListMLE: https://icml.cc/Conferences/2008/papers/167.pdf
"""

import numpy as np
import psycopg2
import json
import hashlib
from datetime import datetime
from typing import List, Dict, Tuple
from tqdm import tqdm

# CEOç¢ºå®š: Î±=0.5 å›ºå®š
ALPHA = 0.5
MAX_ITER = 50  # é«˜é€ŸåŒ–ã®ãŸã‚åæŸã‚’æ—©ã‚ã‚‹
TOL = 1e-3      # åæŸåˆ¤å®šã‚’ç·©ã‚ã‚‹

class PlackettLuceModel:
    """Plackett-Luce Model with Power EP Inference"""
    
    def __init__(self, alpha: float = ALPHA):
        self.alpha = alpha
        self.skills = {}  # horse_id -> (mu, sigma)
        self.convergence_log = []
        
    def fit_listmle(self, race_data: Dict[str, List[Tuple[int, int]]], 
                    max_iter: int = MAX_ITER, tol: float = TOL) -> Dict:
        """
        ListMLEå­¦ç¿’ (ç°¡æ˜“ç‰ˆ)
        race_data: {race_id: [(umaban, rank), ...]}
        """
        print(f"ğŸ¯ Starting ListMLE training (Î±={self.alpha}, max_iter={max_iter}, tol={tol})")
        
        # å…¨é¦¬ã®ã‚¹ã‚­ãƒ«åˆæœŸåŒ–
        all_horses = set()
        for entries in race_data.values():
            for umaban, rank in entries:
                all_horses.add(umaban)
        
        # åˆæœŸã‚¹ã‚­ãƒ«: å¹³å‡0, åˆ†æ•£1
        for horse_id in all_horses:
            self.skills[horse_id] = {'mu': 0.0, 'sigma': 1.0}
        
        print(f"âœ… Initialized {len(self.skills)} horses")
        
        # ListMLEæœ€é©åŒ–ï¼ˆç°¡æ˜“ç‰ˆ: gradient ascentï¼‰
        learning_rate = 0.01
        prev_loss = float('inf')
        
        for iteration in range(max_iter):
            total_loss = 0.0
            gradients = {h: 0.0 for h in all_horses}
            
            # å„ãƒ¬ãƒ¼ã‚¹ã§ã®å°¤åº¦è¨ˆç®—
            for race_id, entries in race_data.items():
                # é †ä½ã§ã‚½ãƒ¼ãƒˆ
                sorted_entries = sorted(entries, key=lambda x: x[1])
                horse_ids = [umaban for umaban, rank in sorted_entries]
                
                # PLå°¤åº¦ã®å‹¾é…è¨ˆç®—
                for i, horse_i in enumerate(horse_ids):
                    # æ®‹ã‚Šé¦¬ã®ã‚¹ã‚­ãƒ«
                    remaining_skills = [self.skills[h]['mu'] for h in horse_ids[i:]]
                    remaining_exp = np.exp(remaining_skills)
                    
                    # log P(horse_i | remaining)
                    skill_i = self.skills[horse_i]['mu']
                    log_prob = skill_i - np.log(np.sum(remaining_exp))
                    total_loss -= log_prob
                    
                    # å‹¾é…: 1 - exp(skill_i) / sum(exp(remaining))
                    prob_i = np.exp(skill_i) / np.sum(remaining_exp)
                    gradients[horse_i] += (1.0 - prob_i)
                    
                    # æ®‹ã‚Šã®é¦¬ã«ã‚‚å‹¾é…ã‚’é…åˆ†
                    for j, horse_j in enumerate(horse_ids[i+1:], start=i+1):
                        prob_j = np.exp(self.skills[horse_j]['mu']) / np.sum(remaining_exp)
                        gradients[horse_j] -= prob_j
            
            # ã‚¹ã‚­ãƒ«æ›´æ–°
            for horse_id in all_horses:
                self.skills[horse_id]['mu'] += learning_rate * gradients[horse_id]
            
            # åæŸåˆ¤å®š
            loss_change = abs(prev_loss - total_loss)
            self.convergence_log.append({
                'iteration': iteration + 1,
                'loss': float(total_loss),
                'loss_change': float(loss_change)
            })
            
            if iteration % 10 == 0:
                print(f"  Iter {iteration+1}/{max_iter}: loss={total_loss:.4f}, change={loss_change:.6f}")
            
            if loss_change < tol:
                print(f"âœ… Converged at iteration {iteration+1}")
                break
                
            prev_loss = total_loss
        
        # æ­£è¦åŒ– (å¹³å‡0)
        mean_skill = np.mean([s['mu'] for s in self.skills.values()])
        for horse_id in self.skills:
            self.skills[horse_id]['mu'] -= mean_skill
        
        return {
            'converged': loss_change < tol,
            'iterations': len(self.convergence_log),
            'final_loss': float(total_loss),
            'num_horses': len(self.skills)
        }
    
    def predict_top5(self, race_entries: List[int]) -> List[Dict]:
        """
        Power EPæ¨è«–ã§Top5ã‚’äºˆæ¸¬
        race_entries: [umaban1, umaban2, ...]
        """
        # ã‚¹ã‚­ãƒ«ã‚’å–å¾—
        skills = []
        for umaban in race_entries:
            if umaban in self.skills:
                skills.append(self.skills[umaban]['mu'])
            else:
                # æœªçŸ¥ã®é¦¬ã¯å¹³å‡ã‚¹ã‚­ãƒ«ï¼ˆ0.0ï¼‰
                skills.append(0.0)
        
        # Power EP (ç°¡æ˜“ç‰ˆ: softmax with temperature)
        # Î±=0.5 ã®å ´åˆã€ã‚¹ã‚­ãƒ«ã‚’ âˆš(skill) ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaled_skills = np.array(skills) * self.alpha
        exp_skills = np.exp(scaled_skills)
        probs = exp_skills / np.sum(exp_skills)
        
        # Top5ã‚’é¸å‡º
        top5_indices = np.argsort(probs)[::-1][:5]
        
        results = []
        for idx in top5_indices:
            umaban = race_entries[idx]
            skill = skills[idx]
            prob = float(probs[idx])
            
            results.append({
                'umaban': int(umaban),
                'skill_mu': float(skill),
                'skill_sigma': float(self.skills.get(umaban, {}).get('sigma', 1.0)),
                'P_win_raw': prob,
                'rank_pred': len(results) + 1
            })
        
        return results


def main():
    """Phase 2A: PL+PowerEP ã§ "å‹•ãæœ€å°" ã‚’ä½œæˆ"""
    print("=" * 60)
    print("Phase 2A: PL+PowerEP Minimal Implementation")
    print("CEO Directive: v1.0 SSOT - å®Œå…¨ãªPL+PowerEPå¿…é ˆ")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    conn = psycopg2.connect(
        host='localhost',
        database='eoi_pl',
        user='postgres',
        password='postgres123'
    )
    cur = conn.cursor()
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆ2024å¹´ã€å°‘æ•°ãƒ¬ãƒ¼ã‚¹ã§ãƒ†ã‚¹ãƒˆï¼‰
    print("\nğŸ“Š Loading training data (2024, 1000 races)...")
    query = '''
    SELECT 
        e.race_id,
        e.umaban,
        e.kakutei_chakujun as rank
    FROM entries e
    INNER JOIN races r ON e.race_id = r.race_id
    WHERE r.race_id LIKE '2024%'
        AND e.kakutei_chakujun IS NOT NULL
        AND e.kakutei_chakujun > 0
        AND e.race_id IN (
            SELECT DISTINCT e2.race_id 
            FROM entries e2
            INNER JOIN races r2 ON e2.race_id = r2.race_id
            WHERE r2.race_id LIKE '2024%'
            ORDER BY e2.race_id 
            LIMIT 1000
        )
    ORDER BY e.race_id, e.kakutei_chakujun
    '''
    
    cur.execute(query)
    rows = cur.fetchall()
    
    # ãƒ¬ãƒ¼ã‚¹å˜ä½ã§ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
    race_data = {}
    for race_id, umaban, rank in rows:
        if race_id not in race_data:
            race_data[race_id] = []
        race_data[race_id].append((umaban, rank))
    
    print(f"âœ… Loaded {len(race_data)} races, {len(rows)} entries")
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    print("\nğŸ“ Training Plackett-Luce model with ListMLE...")
    model = PlackettLuceModel(alpha=ALPHA)
    training_result = model.fit_listmle(race_data, max_iter=MAX_ITER, tol=TOL)
    
    print("\nğŸ“Š Training Results:")
    print(f"  Converged: {training_result['converged']}")
    print(f"  Iterations: {training_result['iterations']}")
    print(f"  Final loss: {training_result['final_loss']:.4f}")
    print(f"  Trained horses: {training_result['num_horses']}")
    
    # ãƒ†ã‚¹ãƒˆ: æ¬¡ã®æ—¥ï¼ˆ2025-01-01ï¼‰ã®äºˆæ¸¬
    print("\nğŸ”® Testing on 2025-01-01 (first 10 races)...")
    test_query = '''
    SELECT 
        e.race_id,
        e.umaban,
        e.bamei,
        e.kakutei_chakujun as actual_rank
    FROM entries e
    INNER JOIN races r ON e.race_id = r.race_id
    WHERE e.race_id LIKE '2025_0101%'
    ORDER BY e.race_id, e.umaban
    LIMIT 120
    '''
    
    cur.execute(test_query)
    test_rows = cur.fetchall()
    
    # ãƒ¬ãƒ¼ã‚¹å˜ä½ã§æ•´ç†
    test_races = {}
    for race_id, umaban, bamei, actual_rank in test_rows:
        if race_id not in test_races:
            test_races[race_id] = {'entries': [], 'names': {}, 'actuals': {}}
        test_races[race_id]['entries'].append(umaban)
        test_races[race_id]['names'][umaban] = bamei
        if actual_rank:
            test_races[race_id]['actuals'][umaban] = actual_rank
    
    # å„ãƒ¬ãƒ¼ã‚¹ã§Top5ã‚’äºˆæ¸¬
    sample_predictions = []
    for race_id, race_info in list(test_races.items())[:3]:  # æœ€åˆã®3ãƒ¬ãƒ¼ã‚¹ã®ã¿è¡¨ç¤º
        entries = race_info['entries']
        top5 = model.predict_top5(entries)
        
        print(f"\n  Race: {race_id}")
        print(f"  Entries: {len(entries)} horses")
        print(f"  Top5 Predictions:")
        for pred in top5:
            umaban = pred['umaban']
            bamei = race_info['names'].get(umaban, 'Unknown')
            actual = race_info['actuals'].get(umaban, 'N/A')
            print(f"    {pred['rank_pred']}. é¦¬ç•ª{umaban:2d} {bamei:12s} "
                  f"P_win={pred['P_win_raw']:.4f} Î¼={pred['skill_mu']:+.3f} "
                  f"(actual: {actual})")
        
        sample_predictions.append({
            'race_id': race_id,
            'top5': top5
        })
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    print("\nğŸ’¾ Saving model...")
    model_data = {
        'skills': {str(k): {'mu': float(v['mu']), 'sigma': float(v['sigma'])} 
                   for k, v in model.skills.items()},
        'alpha': float(model.alpha),
        'training_result': {
            'converged': bool(training_result['converged']),
            'iterations': int(training_result['iterations']),
            'final_loss': float(training_result['final_loss']),
            'num_horses': int(training_result['num_horses'])
        },
        'convergence_log': [{
            'iteration': int(log['iteration']),
            'loss': float(log['loss']),
            'loss_change': float(log['loss_change'])
        } for log in model.convergence_log[:10]]  # æœ€åˆã®10å›åˆ†
    }
    
    with open('/home/user/eoi-pl/models/pl_powerep_model.json', 'w') as f:
        json.dump(model_data, f, indent=2)
    
    print("âœ… Model saved to models/pl_powerep_model.json")
    
    # ç›£æŸ»ãƒ­ã‚°ï¼ˆæœ€å°ç‰ˆï¼‰
    audit_log = {
        'audit_meta': {
            'generated_at': datetime.now().isoformat(),
            'model_version': 'v1.0-PL-PowerEP',
            'phase': '2A_minimal'
        },
        'model_training': {
            'algorithm': 'Plackett-Luce + Power EP',
            'learning_method': 'ListMLE',
            'alpha': float(ALPHA),
            'max_iter': int(MAX_ITER),
            'tol': float(TOL),
            'training_races': int(len(race_data)),
            'training_entries': int(len(rows)),
            'num_horses': int(training_result['num_horses']),
            'converged': bool(training_result['converged']),
            'iterations': int(training_result['iterations']),
            'final_loss': float(training_result['final_loss'])
        },
        'sample_predictions': [{
            'race_id': pred['race_id'],
            'top5': [{
                'umaban': int(horse['umaban']),
                'skill_mu': float(horse['skill_mu']),
                'skill_sigma': float(horse['skill_sigma']),
                'P_win_raw': float(horse['P_win_raw']),
                'rank_pred': int(horse['rank_pred'])
            } for horse in pred['top5']]
        } for pred in sample_predictions[:3]]
    }
    
    with open('/home/user/eoi-pl/data/audit_pl_minimal.json', 'w') as f:
        json.dump(audit_log, f, indent=2)
    
    print("âœ… Audit log saved to data/audit_pl_minimal.json")
    
    conn.close()
    print("\n" + "=" * 60)
    print("âœ… Phase 2A Minimal Implementation Complete!")
    print("=" * 60)


if __name__ == '__main__':
    main()
