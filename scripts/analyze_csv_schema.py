#!/usr/bin/env python3
"""
CSVã‚¹ã‚­ãƒ¼ãƒè§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- ã‚«ãƒ©ãƒ åã€ãƒ‡ãƒ¼ã‚¿å‹ã€æ¬ æå€¤ã®ç¢ºèª
- çµåˆã‚­ãƒ¼ã®æ¤œè¨¼
- ã‚ªãƒƒã‚º/äººæ°—ã‚«ãƒ©ãƒ ã®æœ‰ç„¡ãƒã‚§ãƒƒã‚¯ï¼ˆç¦æ­¢äº‹é …ç¢ºèªï¼‰
"""

import pandas as pd
import sys

def analyze_csv(filepath, name, nrows=10000):
    """CSVåŸºæœ¬æƒ…å ±ã‚’è§£æ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {name} Analysis")
    print(f"{'='*60}")
    
    # ã‚µãƒ³ãƒ—ãƒ«èª­ã¿è¾¼ã¿ï¼ˆå¤§ãã„ãƒ•ã‚¡ã‚¤ãƒ«å¯¾ç­–ï¼‰
    df = pd.read_csv(filepath, nrows=nrows, low_memory=False)
    
    print(f"\nâœ… Shape: {df.shape}")
    print(f"âœ… Columns ({len(df.columns)}): {list(df.columns)}")
    
    print("\nğŸ“‹ Data Types:")
    print(df.dtypes)
    
    print("\nğŸ“‹ Missing Values:")
    missing = df.isnull().sum()
    print(missing[missing > 0])
    
    print("\nğŸ“‹ Sample Data (first 3 rows):")
    print(df.head(3))
    
    # ã‚ªãƒƒã‚º/äººæ°—ã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯ï¼ˆç¦æ­¢äº‹é …ï¼‰
    forbidden_keywords = ['odds', 'ã‚ªãƒƒã‚º', 'äººæ°—', 'ninki', 'popularity']
    forbidden_cols = [col for col in df.columns 
                     if any(kw.lower() in col.lower() for kw in forbidden_keywords)]
    
    if forbidden_cols:
        print(f"\nâš ï¸  WARNING: Potential forbidden columns detected: {forbidden_cols}")
    else:
        print(f"\nâœ… No obvious odds/popularity columns detected")
    
    return df

def verify_join_keys(races_df, entries_df):
    """çµåˆã‚­ãƒ¼ã®æ¤œè¨¼"""
    print(f"\n{'='*60}")
    print("ğŸ”— Join Key Verification")
    print(f"{'='*60}")
    
    join_keys = ['kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'race_bango']
    
    print(f"\nâœ… Join keys: {join_keys}")
    
    # ã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª
    for key in join_keys:
        in_races = key in races_df.columns
        in_entries = key in entries_df.columns
        print(f"  - {key}: races={in_races}, entries={in_entries}")
    
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¬ãƒ¼ã‚¹æ•°
    races_df['race_id'] = (
        races_df['kaisai_nen'].astype(str) + '_' +
        races_df['kaisai_tsukihi'].astype(str).str.zfill(4) + '_' +
        races_df['keibajo_code'].astype(str) + '_' +
        races_df['race_bango'].astype(str).str.zfill(2)
    )
    
    entries_df['race_id'] = (
        entries_df['kaisai_nen'].astype(str) + '_' +
        entries_df['kaisai_tsukihi'].astype(str).str.zfill(4) + '_' +
        entries_df['keibajo_code'].astype(str) + '_' +
        entries_df['race_bango'].astype(str).str.zfill(2)
    )
    
    print(f"\nâœ… Unique races in races.csv: {races_df['race_id'].nunique()}")
    print(f"âœ… Unique races in entries.csv: {entries_df['race_id'].nunique()}")
    
    # çµåˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    races_ids = set(races_df['race_id'])
    entries_ids = set(entries_df['race_id'])
    
    common_ids = races_ids & entries_ids
    only_races = races_ids - entries_ids
    only_entries = entries_ids - races_ids
    
    print(f"\nâœ… Common races: {len(common_ids)}")
    print(f"âš ï¸  Only in races: {len(only_races)}")
    print(f"âš ï¸  Only in entries: {len(only_entries)}")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    if len(common_ids) > 0:
        sample_id = list(common_ids)[0]
        print(f"\nğŸ“‹ Sample race_id: {sample_id}")
        print("\nRaces data:")
        print(races_df[races_df['race_id'] == sample_id])
        print("\nEntries data:")
        print(entries_df[entries_df['race_id'] == sample_id].head(3))

if __name__ == "__main__":
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    races_path = "/home/user/uploaded_files/races_2020_2025.csv"
    entries_path = "/home/user/uploaded_files/entries_results_2020_2025.csv"
    
    # è§£æå®Ÿè¡Œ
    races_df = analyze_csv(races_path, "races_2020_2025.csv", nrows=10000)
    entries_df = analyze_csv(entries_path, "entries_results_2020_2025.csv", nrows=10000)
    
    # çµåˆã‚­ãƒ¼æ¤œè¨¼
    verify_join_keys(races_df, entries_df)
    
    print(f"\n{'='*60}")
    print("âœ… Schema analysis completed")
    print(f"{'='*60}\n")
